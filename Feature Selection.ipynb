{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1hDk9hDvOH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f822e8-7180-46ab-9324-855697636449"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#Change current working directory to gdrive\n",
        "%cd /gdrive\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_k0z66e38lG",
        "outputId": "035c970d-132c-4edc-b318-698621bb4c82"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "#NLTK-------------------------------\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Import libraries for feature \n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMwGQK7KAd7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98252674-a2c1-4090-970d-5aa19a6d6014"
      },
      "source": [
        "#Read files\n",
        "textfile = r'/gdrive/My Drive/TextMining/Comments.csv'\n",
        "textData = pd.read_csv(textfile) #creates a dataframe\n",
        "\n",
        "CustInfofile = r'/gdrive/My Drive/TextMining/Customers.csv'\n",
        "CustInfoData = pd.read_csv(CustInfofile)  #creates a dataframe\n",
        "\n",
        "print(textData.shape)\n",
        "print(CustInfoData.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 2)\n",
            "(2070, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(textData.head)\n",
        "print(CustInfoData.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxRHh_cHRuR4",
        "outputId": "acf11b73-3cd5-44fe-fe8c-436b75db9bfc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of         ID                                           Comments\n",
            "0     1309  Does not like the way the phone works. It is t...\n",
            "1     3556  Wanted to know the nearest store location. Wan...\n",
            "2     2230  Wants to know how to do text messaging. Referr...\n",
            "3     2312  Asked how to disable call waiting. referred hi...\n",
            "4     3327  Needs help learning how to use the phone. I su...\n",
            "...    ...                                                ...\n",
            "2065  3034  Needed help figuring out his bill. I explained...\n",
            "2066   271  He lost his phone and called to cancel service...\n",
            "2067   783  Lost the directions to phone and wants another...\n",
            "2068  1295                           Wants to change address.\n",
            "2069  1807  He lost his phone and called to cancel service...\n",
            "\n",
            "[2070 rows x 2 columns]>\n",
            "<bound method NDFrame.head of         ID Sex Status  Children  Est_Income Car_Owner   Usage        Age  \\\n",
            "0        1   F      S         1    38000.00         N  229.64  24.393333   \n",
            "1        6   M      M         2    29616.00         N   75.29  49.426667   \n",
            "2        8   M      M         0    19732.80         N   47.25  50.673333   \n",
            "3       11   M      S         2       96.33         N   59.01  56.473333   \n",
            "4       14   F      M         2    52004.80         N   28.14  25.140000   \n",
            "...    ...  ..    ...       ...         ...       ...     ...        ...   \n",
            "2065  3821   F      S         0    78851.30         N   29.04  48.373333   \n",
            "2066  3822   F      S         1    17540.70         Y   36.20  62.786667   \n",
            "2067  3823   F      M         0    83891.90         Y   74.40  61.020000   \n",
            "2068  3824   F      M         2    28220.80         N   38.95  38.766667   \n",
            "2069  3825   F      S         0    28589.10         N  100.28  15.600000   \n",
            "\n",
            "      RatePlan  LongDistance  International   Local  Dropped Paymethod  \\\n",
            "0            3         23.56           0.00  206.08        0        CC   \n",
            "1            2         29.78           0.00   45.50        0        CH   \n",
            "2            3         24.81           0.00   22.44        0        CC   \n",
            "3            1         26.13           0.00   32.88        1        CC   \n",
            "4            1          5.03           0.00   23.11        0        CH   \n",
            "...        ...           ...            ...     ...      ...       ...   \n",
            "2065         4          0.37           0.00   28.66        0        CC   \n",
            "2066         1         22.17           0.57   13.45        0      Auto   \n",
            "2067         4         28.92           0.00   45.47        0        CH   \n",
            "2068         4         26.49           0.00   12.46        0        CC   \n",
            "2069         3         13.19           0.00   87.09        0        CC   \n",
            "\n",
            "     LocalBilltype LongDistanceBilltype     TARGET  \n",
            "0           Budget       Intnl_discount  Cancelled  \n",
            "1        FreeLocal             Standard    Current  \n",
            "2        FreeLocal             Standard    Current  \n",
            "3           Budget             Standard    Current  \n",
            "4           Budget       Intnl_discount  Cancelled  \n",
            "...            ...                  ...        ...  \n",
            "2065     FreeLocal             Standard  Cancelled  \n",
            "2066        Budget             Standard  Cancelled  \n",
            "2067        Budget             Standard  Cancelled  \n",
            "2068     FreeLocal             Standard  Cancelled  \n",
            "2069     FreeLocal             Standard  Cancelled  \n",
            "\n",
            "[2070 rows x 17 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWOTk6C1Ao45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98c1619-5a97-47d0-d374-a13f566ba5eb"
      },
      "source": [
        "#Extract target column from Customer Info file\n",
        "y_train = CustInfoData[\"TARGET\"]\n",
        "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
        "                     \n",
        "print(X_train.shape)\n",
        "print(textData.shape)\n",
        "print(textData.head())\n",
        "print(y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 16)\n",
            "(2070, 2)\n",
            "     ID                                           Comments\n",
            "0  1309  Does not like the way the phone works. It is t...\n",
            "1  3556  Wanted to know the nearest store location. Wan...\n",
            "2  2230  Wants to know how to do text messaging. Referr...\n",
            "3  2312  Asked how to disable call waiting. referred hi...\n",
            "4  3327  Needs help learning how to use the phone. I su...\n",
            "0       Cancelled\n",
            "1         Current\n",
            "2         Current\n",
            "3         Current\n",
            "4       Cancelled\n",
            "          ...    \n",
            "2065    Cancelled\n",
            "2066    Cancelled\n",
            "2067    Cancelled\n",
            "2068    Cancelled\n",
            "2069    Cancelled\n",
            "Name: TARGET, Length: 2070, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuWYNz2Ep17l"
      },
      "source": [
        "#Tokenize - Split the sentences to lists of words\n",
        "textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n",
        "\n",
        "export_csv = textData.to_csv(r'/gdrive/My Drive/TextMining/TextDataTokenized1.csv')\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeYXLU-u_v9R"
      },
      "source": [
        "# Use English stemmer.\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "#Now do stemming - create a new dataframe to store stemmed version\n",
        "newTextData=pd.DataFrame()\n",
        "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
        "# we get a column where words have been stemmed, saving it to new file where words are tokenized and stemmed\n",
        "export_csv = newTextData.to_csv(r'/gdrive/My Drive/TextMining/newTextDataTS_SNOWBALL.csv')\n",
        "\n",
        "##comment on 'disable' being 'disabl' in the stemmed words list, misspelled words \"batteri\" \"bateri\" etc\n",
        "## we end up with lot of garbage words\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## use another stemmer now - snowball used earlier \n",
        "# use porter stemmer \n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "newTextData=pd.DataFrame()\n",
        "newTextData=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
        "newTextData['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [ps.stem(y) for y in x]) # Stem every word.\n",
        "# we get a column where words have been stemmed, saving it to new file where words are tokenized and stemmed\n",
        "export_csv = newTextData.to_csv(r'/gdrive/My Drive/TextMining/newTextDataTS_PORTER.csv')"
      ],
      "metadata": {
        "id": "tqUiqDKljN0U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is only a little difference in the working of these two. Words like 'fairly' and 'sportingly' were stemmed to 'fair' and 'sport' in the snowball stemmer but when you use the porter stemmer they are stemmed to 'fairli' and 'sportingli'.O\n",
        "\n",
        "Snowbal stemmer is basically a better version of the porter stemmer\n",
        "so we go ahead with snowball stemmer stemmed strings\n"
      ],
      "metadata": {
        "id": "Gm8z1DZf8Io0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M07E7VW7_y0d"
      },
      "source": [
        "#Join stemmed strings\n",
        "newTextData['CommentsTokenizedStemmed'] = newTextData['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "export_csv = newTextData.to_csv(r'/gdrive/My Drive/TextMining/newTextData-Joined.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBguQloljam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87efab9e-fd20-4b37-f11f-a3bf115278cf"
      },
      "source": [
        "# term document matrix has been constructed here\n",
        "\n",
        "#Do Bag-Of-Words model - Term - Document Matrix\n",
        "#Learn the vocabulary dictionary and return term-document matrix.\n",
        "#count_vect = CountVectorizer(stop_words=None)\n",
        "\n",
        "#stop words have been eliminated here\n",
        "\n",
        "count_vect = CountVectorizer(stop_words='english',lowercase=False) # gets rid of stopwords here as well as does counting #point 2 of todo\n",
        "TD_counts = count_vect.fit_transform(newTextData.CommentsTokenizedStemmed) \n",
        "#after we drop stop words we end up 354 words and the words as shown below, some misspelled etc \n",
        "# we can clean things up on our own if we want to\n",
        "print(TD_counts.shape)\n",
        "print(TD_counts.dtype)\n",
        "print(count_vect.get_feature_names())\n",
        "#print(TD_counts)\n",
        "## does counting for us and now once we get here we get structured data\n",
        "DF_TD_Counts=pd.DataFrame(TD_counts.toarray())\n",
        "print(DF_TD_Counts)\n",
        "export_csv = DF_TD_Counts.to_csv(r'/gdrive/My Drive/TextMining/TD_counts-TokenizedStemmed.csv')\n",
        "\n",
        "## TD_counts-TokenizedStemmed is now in structured form and we got count\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 358)\n",
            "int64\n",
            "['3399', '3g', 'abysm', 'access', 'accessori', 'adapt', 'add', 'addit', 'additon', 'address', 'adit', 'adress', 'advertis', 'afraid', 'alway', 'angel', 'angri', 'ani', 'anoth', 'anyth', 'anytim', 'area', 'asap', 'ask', 'bad', 'basic', 'bateri', 'batteri', 'becaus', 'believ', 'better', 'bigger', 'book', 'bought', 'brain', 'bring', 'built', 'busi', 'button', 'buy', 'cancel', 'cancer', 'car', 'care', 'carrier', 'caus', 'cc', 'cell', 'certain', 'chang', 'charg', 'charger', 'check', 'chip', 'citi', 'claim', 'cleariti', 'cold', 'comapr', 'compani', 'compar', 'competit', 'complain', 'complaint', 'concept', 'connect', 'consisit', 'consist', 'constanli', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cover', 'coverag', 'creat', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'custom', 'customr', 'date', 'day', 'dead', 'decent', 'defect', 'deo', 'did', 'die', 'differ', 'difficult', 'digiti', 'direct', 'disabl', 'doe', 'don', 'dont', 'drop', 'dure', 'easier', 'effect', 'encount', 'end', 'enemi', 'equip', 'everytim', 'everywher', 'evrey', 'exactli', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famili', 'featur', 'fed', 'figur', 'fine', 'fix', 'forev', 'forward', 'friend', 'function', 'furthermor', 'futur', 'gave', 'goat', 'good', 'great', 'gsm', 'ha', 'handset', 'happi', 'hard', 'hardli', 'hate', 'hear', 'heard', 'help', 'hi', 'higher', 'highway', 'hochi', 'hole', 'home', 'hope', 'horribl', 'hous', 'implement', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'june', 'just', 'kid', 'kno', 'know', 'lame', 'later', 'lctn', 'learn', 'leroy', 'like', 'line', 'list', 'lo', 'local', 'locat', 'locatn', 'long', 'lost', 'lot', 'love', 'major', 'make', 'manag', 'mani', 'manual', 'market', 'mean', 'messag', 'metropolitian', 'minut', 'misl', 'mistak', 'model', 'momma', 'mr', 'napeleon', 'near', 'nearest', 'need', 'network', 'new', 'news', 'notic', 'number', 'numer', 'offer', 'old', 'om', 'open', 'option', 'ori', 'ot', 'outbound', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phone', 'piec', 'plan', 'pleas', 'point', 'polici', 'poor', 'possibl', 'probabl', 'problem', 'properli', 'provid', 'provis', 'purpos', 'rate', 'rater', 'realiz', 'realli', 'reason', 'receiv', 'recept', 'recption', 'reenter', 'refer', 'relat', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roll', 'rubbish', 'rude', 'said', 'sale', 'say', 'screen', 'self', 'send', 'servic', 'shitti', 'shut', 'sign', 'signal', 'significantli', 'simm', 'simpli', 'sinc', 'site', 'slow', 'sold', 'someon', 'sometim', 'soon', 'speak', 'speed', 'start', 'static', 'stole', 'store', 'stuff', 'stupid', 'substant', 'subtract', 'suck', 'suggest', 'supervisor', 'support', 'sure', 'surpris', 'suspect', 'suspend', 'switch', 'teach', 'technic', 'tell', 'terribl', 'test', 'text', 'thi', 'think', 'thought', 'ticket', 'till', 'time', 'tire', 'today', 'toilet', 'told', 'tone', 'tower', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'turn', 'uncomfort', 'understand', 'unhappi', 'unlimit', 'unreli', 'unwil', 'upset', 'usag', 'use', 'useless', 'valu', 'veri', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'whi', 'wife', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'york']\n",
            "      0    1    2    3    4    5    6    7    8    9    ...  348  349  350  \\\n",
            "0       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "1       0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
            "2       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "3       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "4       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "2065    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "2066    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "2067    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "2068    0    0    0    0    0    0    0    0    0    1  ...    0    0    0   \n",
            "2069    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
            "\n",
            "      351  352  353  354  355  356  357  \n",
            "0       1    0    0    0    0    0    0  \n",
            "1       0    0    0    0    0    0    0  \n",
            "2       0    0    0    0    0    0    0  \n",
            "3       0    0    0    0    0    0    0  \n",
            "4       0    0    0    0    0    0    0  \n",
            "...   ...  ...  ...  ...  ...  ...  ...  \n",
            "2065    0    0    0    0    0    0    0  \n",
            "2066    0    0    0    0    0    0    0  \n",
            "2067    0    0    0    0    0    0    0  \n",
            "2068    0    0    0    0    0    0    0  \n",
            "2069    0    0    0    0    0    0    0  \n",
            "\n",
            "[2070 rows x 358 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd8TZYnAxQbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494ce690-afd7-4256-e69c-e251c79b1f11"
      },
      "source": [
        "#Compute TF-IDF Matrix\n",
        "# TFIDF matrix has been computed here\n",
        "tfidf_transformer = TfidfTransformer() #weighting of words is done here\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(TD_counts) \n",
        "print(X_train_tfidf.shape)\n",
        "DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray())\n",
        "print(DF_TF_IDF)\n",
        "export_csv= DF_TF_IDF.to_csv(r'/gdrive/My Drive/TextMining/TFIDF_counts-TokenizedStemmed.csv')\n",
        "# still 354 features and we get word weightings, earlier it was purely counts"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 358)\n",
            "      0    1    2    3        4    5    6    7    8         9    ...  348  \\\n",
            "0     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "1     0.0  0.0  0.0  0.0  0.27568  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "2     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "3     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "4     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "...   ...  ...  ...  ...      ...  ...  ...  ...  ...       ...  ...  ...   \n",
            "2065  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "2066  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "2067  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "2068  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.772949  ...  0.0   \n",
            "2069  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
            "\n",
            "      349  350       351  352  353  354  355  356  357  \n",
            "0     0.0  0.0  0.206947  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "1     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "3     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "4     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "...   ...  ...       ...  ...  ...  ...  ...  ...  ...  \n",
            "2065  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2066  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2067  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2068  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2069  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[2070 rows x 358 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now combine the TF-IDF matrix with Customer data. Then do one-hot encoding on the categorical variables.\n",
        "combined_DF_TF_IDF=pd.concat([CustInfoData,DF_TF_IDF], axis=1)"
      ],
      "metadata": {
        "id": "ONHEbnfVxu-B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding\n",
        "\n",
        "#Do one Hot encoding for categorical features\n",
        "## One hot encoding \n",
        "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
        "#X_cat = combined.select_dtypes(exclude=['int','float64'])\n",
        "print(X_cat)\n",
        "combined_one_hot = pd.get_dummies(combined_DF_TF_IDF,columns=X_cat)\n",
        "print(combined_one_hot.shape)\n",
        "export_csv= combined_one_hot.to_csv(r'/gdrive/My Drive/TextMining/combined_one_hot.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nsw40v3voJfH",
        "outputId": "eb6313e9-ff0e-4d9c-e673-f083a79494cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sex', 'Status', 'Car_Owner', 'Paymethod', 'LocalBilltype', 'LongDistanceBilltype']\n",
            "(2070, 383)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_trainf = combined_one_hot.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
        "y_trainf = combined_one_hot[\"TARGET\"]\n",
        "                     \n",
        "print(X_trainf.shape)\n",
        "print(y_trainf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjeOoQ8EodFm",
        "outputId": "e092c4cd-d968-4f83-a6f9-071e967b1ab4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 382)\n",
            "0       Cancelled\n",
            "1         Current\n",
            "2         Current\n",
            "3         Current\n",
            "4       Cancelled\n",
            "          ...    \n",
            "2065    Cancelled\n",
            "2066    Cancelled\n",
            "2067    Cancelled\n",
            "2068    Cancelled\n",
            "2069    Cancelled\n",
            "Name: TARGET, Length: 2070, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2owIUD6_eYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e991bc0-11f2-4803-c2fe-e9d95f55c3fe"
      },
      "source": [
        "#Feature selection FILTER METHOD\n",
        "#Suppose, we select 25 features with top 25 Fisher scores\n",
        "selector = SelectKBest(k=25)  ## try with top 50 and so son\n",
        "#selector = SelectKBest(score_func=chi2, k=50)\n",
        "\n",
        "#new_DF_TF_IDF = SelectKBest(score_func=chi2, k=50).fit_transform(DF_TF_IDF,y_train)\n",
        "new_DF_TF_IDF = selector.fit_transform(X_trainf,y_trainf) #pulling top 25 features\n",
        "print(new_DF_TF_IDF.shape)\n",
        "\n",
        "feature_names_out = selector.get_support(indices=True)\n",
        "print(feature_names_out)\n",
        "\n",
        "DF_TF_IDF_SelectedFeatures= pd.DataFrame(new_DF_TF_IDF)\n",
        "print(DF_TF_IDF_SelectedFeatures)\n",
        "\n",
        "export_csv= DF_TF_IDF_SelectedFeatures.to_csv(r'/gdrive/My Drive/TextMining/TFIDF_counts-Selected Features.csv')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 25)\n",
            "[  1   2   3   6   7   8  24  80 131 199 225 230 252 262 286 327 333 368\n",
            " 369 371 372 375 376 380 381]\n",
            "       0         1       2      3     4       5    6    7        8    9   ...  \\\n",
            "0     1.0  38000.00  229.64  23.56  0.00  206.08  0.0  0.0  0.00000  0.0  ...   \n",
            "1     2.0  29616.00   75.29  29.78  0.00   45.50  0.0  0.0  0.00000  0.0  ...   \n",
            "2     0.0  19732.80   47.25  24.81  0.00   22.44  0.0  0.0  0.00000  0.0  ...   \n",
            "3     2.0     96.33   59.01  26.13  0.00   32.88  0.0  0.0  0.00000  0.0  ...   \n",
            "4     2.0  52004.80   28.14   5.03  0.00   23.11  0.0  0.0  0.00000  0.0  ...   \n",
            "...   ...       ...     ...    ...   ...     ...  ...  ...      ...  ...  ...   \n",
            "2065  0.0  78851.30   29.04   0.37  0.00   28.66  0.0  0.0  0.44341  0.0  ...   \n",
            "2066  1.0  17540.70   36.20  22.17  0.57   13.45  0.0  0.0  0.00000  0.0  ...   \n",
            "2067  0.0  83891.90   74.40  28.92  0.00   45.47  0.0  0.0  0.00000  0.0  ...   \n",
            "2068  2.0  28220.80   38.95  26.49  0.00   12.46  0.0  0.0  0.00000  0.0  ...   \n",
            "2069  0.0  28589.10  100.28  13.19  0.00   87.09  0.0  0.0  0.00000  0.0  ...   \n",
            "\n",
            "       15   16   17   18   19   20   21   22   23   24  \n",
            "0     0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  \n",
            "1     0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
            "2     0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
            "3     0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
            "4     0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
            "2065  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
            "2066  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  \n",
            "2067  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
            "2068  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
            "2069  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
            "\n",
            "[2070 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_index = selector.get_support(True)\n",
        "print (\"feature index =\", feature_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RejDm2ubpGMK",
        "outputId": "7c5a854e-deb6-454b-c504-f6d00fae06c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature index = [  1   2   3   6   7   8  24  80 131 199 225 230 252 262 286 327 333 368\n",
            " 369 371 372 375 376 380 381]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature selection 50 features\n",
        "#Suppose, we select 50 features with top 50 Fisher scores\n",
        "selector = SelectKBest(k=50)\n",
        "#selector = SelectKBest(score_func=chi2, k=30)\n",
        "\n",
        "#new_DF_TF_IDF = SelectKBest(score_func=chi2, k=50).fit_transform(DF_TF_IDF,y_train)\n",
        "new_DF = selector.fit_transform(X_trainf,y_trainf)\n",
        "print(new_DF.shape)\n",
        "\n",
        "feature_names_out = selector.get_support(indices=True)\n",
        "print(feature_names_out)\n",
        "\n",
        "DF_TF_IDF_SelectedFeatures50= pd.DataFrame(new_DF)\n",
        "print(DF_TF_IDF_SelectedFeatures50)\n",
        "\n",
        "\n",
        "export_csv= DF_TF_IDF_SelectedFeatures50.to_csv(r'/gdrive/My Drive/TextMining/TFIDF_counts-Selected Features_50.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WJa7ZhtpaJH",
        "outputId": "746ac1f1-50ef-41e0-db61-5bba8276a44e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2070, 50)\n",
            "[  1   2   3   6   7   8   9  10  24  45  59  60  61  72  80  91 125 128\n",
            " 131 140 185 199 203 225 226 230 234 235 248 252 257 261 262 267 272 286\n",
            " 321 327 329 333 352 356 368 369 371 372 375 376 380 381]\n",
            "       0         1       2      3     4       5    6    7    8    9   ...  \\\n",
            "0     1.0  38000.00  229.64  23.56  0.00  206.08  0.0  0.0  0.0  0.0  ...   \n",
            "1     2.0  29616.00   75.29  29.78  0.00   45.50  0.0  0.0  0.0  0.0  ...   \n",
            "2     0.0  19732.80   47.25  24.81  0.00   22.44  0.0  0.0  0.0  0.0  ...   \n",
            "3     2.0     96.33   59.01  26.13  0.00   32.88  1.0  0.0  0.0  0.0  ...   \n",
            "4     2.0  52004.80   28.14   5.03  0.00   23.11  0.0  0.0  0.0  0.0  ...   \n",
            "...   ...       ...     ...    ...   ...     ...  ...  ...  ...  ...  ...   \n",
            "2065  0.0  78851.30   29.04   0.37  0.00   28.66  0.0  0.0  0.0  0.0  ...   \n",
            "2066  1.0  17540.70   36.20  22.17  0.57   13.45  0.0  0.0  0.0  0.0  ...   \n",
            "2067  0.0  83891.90   74.40  28.92  0.00   45.47  0.0  0.0  0.0  0.0  ...   \n",
            "2068  2.0  28220.80   38.95  26.49  0.00   12.46  0.0  0.0  0.0  0.0  ...   \n",
            "2069  0.0  28589.10  100.28  13.19  0.00   87.09  0.0  0.0  0.0  0.0  ...   \n",
            "\n",
            "       40   41   42   43   44   45   46   47   48   49  \n",
            "0     0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  \n",
            "1     0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
            "2     0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
            "3     0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
            "4     0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
            "2065  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
            "2066  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  \n",
            "2067  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
            "2068  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
            "2069  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
            "\n",
            "[2070 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_index = selector.get_support(True)\n",
        "print (\"feature index =\", feature_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ11qZywpqNq",
        "outputId": "18828ffe-8771-406f-e33b-0524e9d01793"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature index = [  1   2   3   6   7   8   9  10  24  45  59  60  61  72  80  91 125 128\n",
            " 131 140 185 199 203 225 226 230 234 235 248 252 257 261 262 267 272 286\n",
            " 321 327 329 333 352 356 368 369 371 372 375 376 380 381]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Do feature selection - Wrapper using a Decision Tree classification model\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
        "\n",
        "dt = dt.fit(X_trainf,y_trainf)\n",
        "#print(clf.feature_importances_)\n",
        "\n",
        "model = SelectFromModel(dt, prefit=True, max_features=10, threshold=-np.inf)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "X_new2 = model.transform(X_trainf)\n",
        "X_new_SelectedFeaturesdt= pd.DataFrame(X_new2)\n",
        "export_csv= X_new_SelectedFeaturesdt.to_csv(r'/gdrive/My Drive/TextMining/dt_selectedfeatures_wrapper.csv')\n",
        "#print(model.get_support())\n",
        "print(X_new_SelectedFeaturesdt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otbVk_E0qClT",
        "outputId": "d234cff2-758a-4e30-9881-79042e557e6a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           0    1         2          3      4     5       6    7    8    9\n",
            "0        1.0  1.0  38000.00  24.393333  23.56  0.00  206.08  0.0  1.0  0.0\n",
            "1        6.0  2.0  29616.00  49.426667  29.78  0.00   45.50  1.0  0.0  0.0\n",
            "2        8.0  0.0  19732.80  50.673333  24.81  0.00   22.44  1.0  0.0  0.0\n",
            "3       11.0  2.0     96.33  56.473333  26.13  0.00   32.88  0.0  1.0  0.0\n",
            "4       14.0  2.0  52004.80  25.140000   5.03  0.00   23.11  1.0  0.0  0.0\n",
            "...      ...  ...       ...        ...    ...   ...     ...  ...  ...  ...\n",
            "2065  3821.0  0.0  78851.30  48.373333   0.37  0.00   28.66  0.0  1.0  0.0\n",
            "2066  3822.0  1.0  17540.70  62.786667  22.17  0.57   13.45  0.0  1.0  1.0\n",
            "2067  3823.0  0.0  83891.90  61.020000  28.92  0.00   45.47  1.0  0.0  0.0\n",
            "2068  3824.0  2.0  28220.80  38.766667  26.49  0.00   12.46  1.0  0.0  0.0\n",
            "2069  3825.0  0.0  28589.10  15.600000  13.19  0.00   87.09  0.0  1.0  0.0\n",
            "\n",
            "[2070 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Do feature selection - Wrapper using a RF classification model\n",
        "\n",
        "rf = RandomForestClassifier(max_depth=5, random_state=0)\n",
        "\n",
        "rf = rf.fit(X_trainf,y_trainf)\n",
        "#print(clf.feature_importances_)\n",
        "\n",
        "model = SelectFromModel(rf, prefit=True, max_features=10, threshold=-np.inf)\n",
        "#model = SelectFromModel(clf, prefit=True)\n",
        "X_new = model.transform(X_trainf)\n",
        "X_new_SelectedFeaturesRF= pd.DataFrame(X_new)\n",
        "export_csv= X_new_SelectedFeaturesRF.to_csv(r'/gdrive/My Drive/TextMining/rf_selectedfeatures_wrapper.csv')\n",
        "#print(model.get_support())\n",
        "print(X_new_SelectedFeaturesRF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voAG5ge6pwPE",
        "outputId": "30e797e3-b136-4e0d-93c1-226a87e9e12a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0         1       2          3      4     5       6    7    8    9\n",
            "0     1.0  38000.00  229.64  24.393333  23.56  0.00  206.08  0.0  0.0  1.0\n",
            "1     2.0  29616.00   75.29  49.426667  29.78  0.00   45.50  1.0  1.0  0.0\n",
            "2     0.0  19732.80   47.25  50.673333  24.81  0.00   22.44  1.0  1.0  0.0\n",
            "3     2.0     96.33   59.01  56.473333  26.13  0.00   32.88  1.0  0.0  1.0\n",
            "4     2.0  52004.80   28.14  25.140000   5.03  0.00   23.11  0.0  1.0  0.0\n",
            "...   ...       ...     ...        ...    ...   ...     ...  ...  ...  ...\n",
            "2065  0.0  78851.30   29.04  48.373333   0.37  0.00   28.66  0.0  0.0  1.0\n",
            "2066  1.0  17540.70   36.20  62.786667  22.17  0.57   13.45  0.0  0.0  1.0\n",
            "2067  0.0  83891.90   74.40  61.020000  28.92  0.00   45.47  0.0  1.0  0.0\n",
            "2068  2.0  28220.80   38.95  38.766667  26.49  0.00   12.46  0.0  1.0  0.0\n",
            "2069  0.0  28589.10  100.28  15.600000  13.19  0.00   87.09  0.0  0.0  1.0\n",
            "\n",
            "[2070 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_support()\n",
        "#Get column names\n",
        "cols = model.get_support(indices=True) #get column indices\n",
        "print(\"\\n cols = \", cols, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWOGODrPqYIv",
        "outputId": "036104e6-7469-48ad-9381-5eb83b6d34ae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " cols =  [  1   2   3   4   6   7   8 369 371 372] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 1\n",
        "#feature selection k=25\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train25, X_test25, y_train25, y_test25 = train_test_split(DF_TF_IDF_SelectedFeatures,y_trainf, test_size=0.20, random_state=1)"
      ],
      "metadata": {
        "id": "A-etkvxSqbms"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train25, y_train25)\n",
        "rf_predict = rf.predict(X_test25)\n",
        "\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test25,rf_predict))\n",
        "print(\"Confusion Matrix for Random Forest:\")\n",
        "print(confusion_matrix(y_test25,rf_predict))\n",
        "print('Printing the precision and recall, among other metrics')\n",
        "print(metrics.classification_report(y_test25,rf_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIy_IogasBsh",
        "outputId": "60049fba-6975-4622-af49-800cea124015"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8647342995169082\n",
            "Confusion Matrix for Random Forest:\n",
            "[[124  26]\n",
            " [ 30 234]]\n",
            "Printing the precision and recall, among other metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.81      0.83      0.82       150\n",
            "     Current       0.90      0.89      0.89       264\n",
            "\n",
            "    accuracy                           0.86       414\n",
            "   macro avg       0.85      0.86      0.85       414\n",
            "weighted avg       0.87      0.86      0.87       414\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train25, y_train25)\n",
        "dt_predict = dt.predict(X_test25)\n",
        "\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test25,dt_predict))\n",
        "print(\"Confusion Matrix for Random Forest:\")\n",
        "print(confusion_matrix(y_test25,dt_predict))\n",
        "print('Printing the precision and recall, among other metrics')\n",
        "print(metrics.classification_report(y_test25,dt_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKctnikNuijt",
        "outputId": "bac501f6-6449-4789-8d60-9458e35738bf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8599033816425121\n",
            "Confusion Matrix for Random Forest:\n",
            "[[131  19]\n",
            " [ 39 225]]\n",
            "Printing the precision and recall, among other metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.77      0.87      0.82       150\n",
            "     Current       0.92      0.85      0.89       264\n",
            "\n",
            "    accuracy                           0.86       414\n",
            "   macro avg       0.85      0.86      0.85       414\n",
            "weighted avg       0.87      0.86      0.86       414\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with 50 features\n",
        "X_train50, X_test50, y_train50, y_test50 = train_test_split(DF_TF_IDF_SelectedFeatures50,y_trainf, test_size=0.20, random_state=1)"
      ],
      "metadata": {
        "id": "KAl6-BktvHyH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train50, y_train50)\n",
        "rf_predict = rf.predict(X_test50)\n",
        "\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test50,rf_predict))\n",
        "print(\"Confusion Matrix for Decision Tree:\")\n",
        "print(confusion_matrix(y_test50,rf_predict))\n",
        "print('Printing the precision and recall, among other metrics')\n",
        "print(metrics.classification_report(y_test50,rf_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv-aXaH3vVni",
        "outputId": "c7249214-82c8-4d62-82bc-e1ed4ea9f4c5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8623188405797102\n",
            "Confusion Matrix for Decision Tree:\n",
            "[[124  26]\n",
            " [ 31 233]]\n",
            "Printing the precision and recall, among other metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.80      0.83      0.81       150\n",
            "     Current       0.90      0.88      0.89       264\n",
            "\n",
            "    accuracy                           0.86       414\n",
            "   macro avg       0.85      0.85      0.85       414\n",
            "weighted avg       0.86      0.86      0.86       414\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train50, y_train50)\n",
        "dtc_predict =dtc.predict(X_test50)\n",
        "\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test50,dtc_predict))\n",
        "print(\"Confusion Matrix for Decision Tree:\")\n",
        "print(confusion_matrix(y_test50,dtc_predict))\n",
        "print('Printing the precision and recall, among other metrics')\n",
        "print(metrics.classification_report(y_test50,dtc_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kc7g5EzvVq1",
        "outputId": "efe9f02f-5823-410e-e10f-a5c739afacec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8429951690821256\n",
            "Confusion Matrix for Decision Tree:\n",
            "[[126  24]\n",
            " [ 41 223]]\n",
            "Printing the precision and recall, among other metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.75      0.84      0.79       150\n",
            "     Current       0.90      0.84      0.87       264\n",
            "\n",
            "    accuracy                           0.84       414\n",
            "   macro avg       0.83      0.84      0.83       414\n",
            "weighted avg       0.85      0.84      0.84       414\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## WRAPPER METHOD Random Forest \n",
        "X_trainRF, X_testRF, y_trainRF, y_testRF = train_test_split(X_new_SelectedFeaturesRF,y_train, test_size=0.20, random_state=1)"
      ],
      "metadata": {
        "id": "1C2AIBgVvVuS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_trainRF, y_trainRF)\n",
        "rf_predict = rf.predict(X_testRF)\n",
        "\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_testRF,rf_predict))\n",
        "print(\"Confusion Matrix for Decision Tree:\")\n",
        "print(confusion_matrix(y_testRF,rf_predict))\n",
        "print('Printing the precision and recall, among other metrics')\n",
        "print(metrics.classification_report(y_testRF,rf_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9BYiwOUvVxD",
        "outputId": "7dba38bc-00d5-4fa3-f921-f3481e7702ad"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8743961352657005\n",
            "Confusion Matrix for Decision Tree:\n",
            "[[126  24]\n",
            " [ 28 236]]\n",
            "Printing the precision and recall, among other metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.82      0.84      0.83       150\n",
            "     Current       0.91      0.89      0.90       264\n",
            "\n",
            "    accuracy                           0.87       414\n",
            "   macro avg       0.86      0.87      0.86       414\n",
            "weighted avg       0.88      0.87      0.87       414\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_trainRF, y_trainRF)\n",
        "dt_predict = dt.predict(X_testRF)\n",
        "\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_testRF,dt_predict))\n",
        "print(\"Confusion Matrix for Decision Tree:\")\n",
        "print(confusion_matrix(y_testRF,rf_predict))\n",
        "print('Printing the precision and recall, among other metrics')\n",
        "print(metrics.classification_report(y_testRF,rf_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_imOxK1wDf8",
        "outputId": "0949efcf-bb9e-4e0b-a461-cbca3c20347d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8647342995169082\n",
            "Confusion Matrix for Decision Tree:\n",
            "[[126  24]\n",
            " [ 28 236]]\n",
            "Printing the precision and recall, among other metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.82      0.84      0.83       150\n",
            "     Current       0.91      0.89      0.90       264\n",
            "\n",
            "    accuracy                           0.87       414\n",
            "   macro avg       0.86      0.87      0.86       414\n",
            "weighted avg       0.88      0.87      0.87       414\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## WRAPPER METHOD DT\n",
        "X_trainDT, X_testDT, y_trainDT, y_testDT = train_test_split(X_new_SelectedFeaturesdt,y_train, test_size=0.20, random_state=1)"
      ],
      "metadata": {
        "id": "xCIjfSQUvV0u"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_trainDT, y_trainDT)\n",
        "rf_predict = rf.predict(X_testDT)\n",
        "\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_testDT,rf_predict))\n",
        "print(\"Confusion Matrix for Decision Tree:\")\n",
        "print(confusion_matrix(y_testDT,rf_predict))\n",
        "print('Printing the precision and recall, among other metrics')\n",
        "print(metrics.classification_report(y_testDT,rf_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfBwZYvJvV4V",
        "outputId": "ae040c3f-b6bb-4c99-df85-69b0a5f1f3e0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6328502415458938\n",
            "Confusion Matrix for Decision Tree:\n",
            "[[ 19 131]\n",
            " [ 21 243]]\n",
            "Printing the precision and recall, among other metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.47      0.13      0.20       150\n",
            "     Current       0.65      0.92      0.76       264\n",
            "\n",
            "    accuracy                           0.63       414\n",
            "   macro avg       0.56      0.52      0.48       414\n",
            "weighted avg       0.59      0.63      0.56       414\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_trainDT, y_train25)\n",
        "rf_predict = rf.predict(X_testRF)\n",
        "\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_testDT,rf_predict))\n",
        "print(\"Confusion Matrix for Decision Tree:\")\n",
        "print(confusion_matrix(y_testDT,rf_predict))\n",
        "print('Printing the precision and recall, among other metrics')\n",
        "print(metrics.classification_report(y_testDT,rf_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2l6gPybwBlL",
        "outputId": "11c9ecad-3cb2-4685-f685-809c6ff2770e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6304347826086957\n",
            "Confusion Matrix for Decision Tree:\n",
            "[[  3 147]\n",
            " [  6 258]]\n",
            "Printing the precision and recall, among other metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cancelled       0.33      0.02      0.04       150\n",
            "     Current       0.64      0.98      0.77       264\n",
            "\n",
            "    accuracy                           0.63       414\n",
            "   macro avg       0.49      0.50      0.40       414\n",
            "weighted avg       0.53      0.63      0.51       414\n",
            "\n"
          ]
        }
      ]
    }
  ]
}